{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayush-thakur02/LCM-LoRA/blob/main/LCM_LoRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"justify\" markdown=1>\n",
        "\n",
        "# LCM LoRA Colab Notebook || Github - @ayush-thakur02\n",
        "\n",
        "This Python Notebook is designed for running the LCM LoRA models on Google Colab with a T4 GPU. These open-source models are entirely free for you to use as much as you'd like, enabling you to synthesize high-resolution images with few-step inference. LCM LoRA models include <b>SD v1.5, SDXL, and SSD 1B</b>, which are based on stable diffusion models with LoRA distillation. Don't forget to share this resource with your friends, and happy synthesizing! ðŸ˜ƒ\n",
        "\n",
        "---\n",
        "\n",
        "### Make Sure to follow me:\n",
        "\n",
        "[![Github](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/ayush-thakur02)\n",
        "[![BioLink](https://img.shields.io/badge/bio.link-000000%7D?style=for-the-badge&logo=biolink&logoColor=white)](https://bio.link/ayush_thakur02)\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "45krJ7CeacK_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftRY4sM5SGme"
      },
      "outputs": [],
      "source": [
        "%pip install --quiet --upgrade diffusers accelerate gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Select your Favourite Model\n",
        "SD_Models = \"stabilityai/stable-diffusion-xl-base-1.0\" # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\",\"segmind/SSD-1B\"]\n",
        "LoRA_Models = \"latent-consistency/lcm-lora-sdxl\" # @param [\"latent-consistency/lcm-lora-sdxl\",\"latent-consistency/lcm-lora-sdv1-5\",\"latent-consistency/lcm-lora-ssd-1b\"]\n",
        "\n",
        "from diffusers import DiffusionPipeline, LCMScheduler\n",
        "import torch\n",
        "import time\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    SD_Models,\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True,\n",
        "    variant=\"fp16\",\n",
        "    )\n",
        "\n",
        "pipe.load_lora_weights(LoRA_Models)\n",
        "pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "pipe = pipe.to(\"cuda\", dtype=torch.float16)"
      ],
      "metadata": {
        "id": "6UxIUzONXy4M",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Enter your Prompt and Run\n",
        "Prompt = \"close protrait of a beautiful girl, blue, pink hair style\" # @param {type:\"string\"}\n",
        "No_of_Steps = 4 # @param {type:\"integer\"}\n",
        "Guidance_Scale = 1 # @param {type:\"number\"}\n",
        "\n",
        "start_time = time.time()\n",
        "images = pipe(\n",
        "    prompt=Prompt,\n",
        "    num_inference_steps=No_of_Steps,\n",
        "    guidance_scale=Guidance_Scale,\n",
        ").images[0]\n",
        "end_time = time.time()\n",
        "\n",
        "total_time = end_time - start_time\n",
        "print(f\"Total time taken for Generating Image: {total_time} seconds\\n\")\n",
        "images"
      ],
      "metadata": {
        "id": "u_SY5fnWX4ir",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio Interface"
      ],
      "metadata": {
        "id": "Fselp2Pdhj94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Select Model and Run it\n",
        "SD_Models = \"stabilityai/stable-diffusion-xl-base-1.0\" # @param [\"stabilityai/stable-diffusion-xl-base-1.0\", \"runwayml/stable-diffusion-v1-5\",\"segmind/SSD-1B\"]\n",
        "LoRA_Models = \"latent-consistency/lcm-lora-sdxl\" # @param [\"latent-consistency/lcm-lora-sdxl\",\"latent-consistency/lcm-lora-sdv1-5\",\"latent-consistency/lcm-lora-ssd-1b\"]\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "from diffusers import DiffusionPipeline, LCMScheduler\n",
        "import torch\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    SD_Models,\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True,\n",
        "    variant=\"fp16\",\n",
        ")\n",
        "\n",
        "pipe.load_lora_weights(LoRA_Models)\n",
        "pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "pipe = pipe.to(\"cuda\", dtype=torch.float16)\n",
        "\n",
        "def perform_inference(inp):\n",
        "    if len(inp) >= 4:\n",
        "        prompt = inp\n",
        "        images = pipe(\n",
        "            prompt=prompt,\n",
        "            num_inference_steps=4,\n",
        "            guidance_scale=1,\n",
        "        ).images[0]\n",
        "        return images\n",
        "\n",
        "demo = gr.Interface(fn=perform_inference, inputs=\"text\", outputs=\"image\", allow_flagging=False, live=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(share=True)"
      ],
      "metadata": {
        "id": "V1A-F6PogJhi",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}